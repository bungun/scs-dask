{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "import numpy as np\n",
    "import dask \n",
    "import dask.array as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import multipledispatch\n",
    "import functools\n",
    "namespace_cones = dict()\n",
    "dispatch = functools.partial(multipledispatch.dispatch, namespace=namespace_cones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ConvexCone(object):\n",
    "    def __init__(self, dimension):\n",
    "        self.dim = int(dimension)\n",
    "        \n",
    "    def __dask_tokenize__(self):\n",
    "        return (type(self), self.dim)\n",
    "\n",
    "class ZeroCone(ConvexCone):\n",
    "    pass\n",
    "\n",
    "class ZeroDualCone(ConvexCone):\n",
    "    pass\n",
    "\n",
    "class NonnegativeCone(ConvexCone):\n",
    "    def __init__(self, dimension):\n",
    "        ConvexCone.__init__(self, dimension)\n",
    "\n",
    "NonnegativeDualCone = NonnegativeCone\n",
    "\n",
    "class SecondOrderCone(ConvexCone):\n",
    "    pass\n",
    "\n",
    "SecondOrderDualCone = SecondOrderCone\n",
    "\n",
    "class PositiveSemidefiniteCone(ConvexCone):\n",
    "    pass\n",
    "\n",
    "PositiveSemidefiniteDualCone = PositiveSemidefiniteCone\n",
    "PSDCone = PositiveSemidefiniteCone\n",
    "\n",
    "# exp(x)\n",
    "# perspective: y*exp(x/y), y > 0\n",
    "# K = epi[(y*exp(x/y)), y > 0] = {(x, y, z) | y*exp(x/y) >= z, y > 0}\n",
    "# K_exp = cl(K) = K \\cup {(x, 0, z) \\in R^3| x =< 0, z >= 0}\n",
    "class ExponentialCone(ConvexCone):\n",
    "    pass\n",
    "\n",
    "# K_exp^* = {(u, v, w) \\in R_- \\times R \\times R_+ | -ulog(-u/w) + u - v <= 0}\n",
    "#           \\cup {(0, v, w) | v >= 0, w >= 0}\n",
    "class ExponentialDualCone(ConvexCone):\n",
    "    pass\n",
    "\n",
    "class PowerCone(ConvexCone):\n",
    "    def __init__(self, powers):\n",
    "        powers = np.array(powers)\n",
    "        assert all(abs(powers) <= 1)\n",
    "        ConvexCone.__init__(self, len(powers))\n",
    "        self.powers = powers\n",
    "           \n",
    "class PowerDualCone(PowerCone):\n",
    "    def __init__(self, powers):\n",
    "        PowerCone.__init__(self, -1 * np.array(powers))\n",
    "        \n",
    "CONES = (\n",
    "    'Zero',\n",
    "    'Nonnegative',\n",
    "    'SecondOrder',\n",
    "    'PositiveSemidefinite',\n",
    "    'Exponential',\n",
    "    'Power')\n",
    "DUAL_CONES = {eval(nm + 'Cone'): eval(nm + 'DualCone') for nm in CONES}\n",
    "DUAL_CONES.update({dc: pc for (pc, dc) in DUAL_CONES.items()})\n",
    "def K_to_Kstar(K):\n",
    "    return DUAL_CONES[type(K)](K.dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@dispatch(ZeroCone, (np.ndarray, da.Array))\n",
    "def project_cone(K, x):\n",
    "    return 0 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@dispatch(ZeroDualCone, (np.ndarray, da.Array))\n",
    "def project_cone(K, x):\n",
    "    return 1 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@dispatch(NonnegativeCone, np.ndarray)\n",
    "def project_cone(K, x):\n",
    "    return np.maximum(x, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@dispatch(NonnegativeCone, da.Array)\n",
    "def project_cone(K, x):\n",
    "    return da.maximum(x, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@dispatch(SecondOrderCone, np.ndarray)\n",
    "def project_cone(K, x):\n",
    "    s, v = x[0, ...], x[1:, ...]\n",
    "    norm_v = np.linalg.norm(v)\n",
    "    if norm_v <= -s:\n",
    "        return 0 * x\n",
    "    elif norm_v <= s:\n",
    "        return 1 * x\n",
    "    else:\n",
    "        return 0.5*(1 + s/norm_v) * np.hstack(([norm_v], v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@dispatch(SecondOrderCone, da.Array)\n",
    "def project_cone(K, x):\n",
    "    s = x[0].compute()\n",
    "    v = x[1:]\n",
    "    norm_v = da.linalg.norm(v).compute()\n",
    "    \n",
    "    if norm_v <= -s:\n",
    "        projx = 0 * x\n",
    "    elif norm_v <= s:\n",
    "        projx = 1 * x\n",
    "    else:\n",
    "        scal = 0.5 * (1 + s/norm_v)\n",
    "        s = da.from_array(np.array([norm_v]), chunks=(1,))\n",
    "        projx = scal * da.hstack((s, v))\n",
    "    return projx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@dispatch(PositiveSemidefiniteCone, np.ndarray)\n",
    "def project_cone(K, x):\n",
    "    L, Q = np.linalg.eigh(np.reshape(x, (K.dim, K.dim)))\n",
    "    return (Q.dot(np.maximum(0, L).reshape(-1, 1) * Q.T)).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@dispatch(PositiveSemidefiniteCone, da.Array)\n",
    "def project_cone(K, x):\n",
    "    assert x.size == K.dim**2, 'input dimension compatible'\n",
    "    chunks = x[:K.dim].chunks[0]\n",
    "    X = da.reshape(x, (K.dim, K.dim)).rechunk((chunks, (K.dim,)))\n",
    "    U, S, V = da.linalg.svd(da.reshape(x, (K.dim, K.dim)))\n",
    "    return U.dot(da.maximum(0, S).reshape(-1, 1) * V).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CONE_TOL = 1e-8\n",
    "CONE_THRESH = 1e-6 \n",
    "EXP_CONE_MAX_ITERS = 100\n",
    "\n",
    "def exp_solve_fixed_rho(v0, v, rho):\n",
    "    \"\"\" Solve scalarized cone projection problem for fixed Lagrange multiplier rho > 0.\n",
    "    \n",
    "        We can solve\n",
    "    \n",
    "            argmin g(x, y, z) = 0.5(x-x0)^2 + 0.5 (y-y0)^2 + 0.5(z-z0)^2 + x0 - rho * ylog(z/y)\n",
    "            \n",
    "        by using the optimality conditions:\n",
    "        \n",
    "            g_x = 0 = x - x0 + rho\n",
    "            g_y = 0 = y - y0 - rho log(z/y) + rho\n",
    "            g_z = 0 = z - z0 - rho y/z.\n",
    "            \n",
    "        Substitute rho y = z(z-z0) in [2]:\n",
    "        \n",
    "            g_y = 0 = (1/rho)z(z-z0) -y0 + rho log((z-z0)/rho) + rho,\n",
    "                    = (1/rho^2)z(z-z0) -y0/rho + log((z-z0)/rho) + 1,\n",
    "\n",
    "        Let t = z-z0 and define f: R->R as\n",
    "        \n",
    "            f(t) = t(t+z0)/rho^2 - y0/rho + log(t/rho) + 1.\n",
    "            \n",
    "        Find t such that f(t) = 0 by Newton Raphson.\n",
    "        \n",
    "        Take z_init = 0 -> t_init = 0 - z0. Take t_init = max(epsilon, -z0) for domain of log().\n",
    "        \n",
    "        Solution v^star = (x^star, y^star, z^star) is then: \n",
    "        \n",
    "            z^star = t^star + z0\n",
    "            y^star = (1/rho) * z^star(z^star - z0) = (1/rho) * t^star * z^star\n",
    "            x^star = x0 - rho\n",
    "    \"\"\"\n",
    "    x0, y0, z0 = v0\n",
    "    ti = max(-z0, 1e-6)\n",
    "    f = lambda t: (1/rho**2)*t*(t+z0) - y0/rho + np.log(t/rho) + 1\n",
    "    df = lambda t: (2*t + z0)/rho**2 + 1/t\n",
    "    for i in range(EXP_CONE_MAX_ITERS):\n",
    "        fi = f(ti)\n",
    "        ti -= fi / df(ti)\n",
    "        if (ti <= -z0):\n",
    "            return 0 * z0\n",
    "        elif (ti <= 0):\n",
    "            return z0\n",
    "        elif abs(fi) < CONE_TOL:\n",
    "            break \n",
    "    t_star = ti\n",
    "    z_star = t_star + z0\n",
    "\n",
    "    v[2] = t_star\n",
    "    v[1] = t_star * z_star / rho\n",
    "    v[0] = x0 - rho\n",
    "    return v\n",
    "\n",
    "def exp_grad_rho(v0, v, rho):\n",
    "    \"\"\" \n",
    "    Evaluate gradient of L(v, rho) w.r.t to rho.\n",
    "    \n",
    "    Set v = argmin L(v) = |v-v0|_2 + rho g(v) for fixed rho > 0.\n",
    "    Let (r, s, t) = v. Then\n",
    "    \n",
    "        L_rho = g(v) = r - s log(t/s), s > epsilon\n",
    "                     = 0             , otherwise\n",
    "    \"\"\"\n",
    "    v = exp_solve_fixed_rho(v0, v, rho)\n",
    "    r, s, t = v\n",
    "    if (s <= 1e-12):\n",
    "        g = r\n",
    "    else:\n",
    "        g = r + s * np.log(s/t)\n",
    "    return g, v\n",
    "\n",
    "def exp_rho_bounds(v0, v):\n",
    "    \"\"\"\n",
    "    Initialize bounds for bisection search for optimal rho.\n",
    "    \n",
    "    Set lower bound = 0\n",
    "    Find upper bound by doubling rho until minimizing\n",
    "    \n",
    "        |v - v0|_2^2 + rho g(v)\n",
    "        \n",
    "    yields a solution v such that g(v) < 0.\n",
    "    \"\"\"\n",
    "    lb_rho = 0.\n",
    "    ub_rho = 0.125\n",
    "    g, v = exp_grad_rho(v0, v, ub_rho)\n",
    "    while g > 0:\n",
    "        lb_rho = ub_rho\n",
    "        ub_rho *= 2\n",
    "        g, v = exp_grad_rho(v0, v, ub_rho)\n",
    "    return lb_rho, ub_rho, v\n",
    "\n",
    "# r * exp(s/r) <= t\n",
    "def v_in_Kexp(v):\n",
    "    \"\"\"\n",
    "    Test whether v lies in exponential primal cone\n",
    "    \"\"\"\n",
    "    r, s, t = v\n",
    "    return ((r <= 0 and s == 0 and t >= 0)\n",
    "             or (s > 0 and s*np.exp(r/s) - t <= CONE_THRESH))\n",
    "\n",
    "# -r * exp(s/r) <= t*exp(1)\n",
    "def negv_in_Kexp_star(v):\n",
    "    \"\"\"\n",
    "    Test whether v lies in exponential dual cone\n",
    "    \"\"\"\n",
    "    r, s, t = -v\n",
    "    return ((r == 0 and s >= 0 and t >= 0)\n",
    "            or (r < 0 and t >=0 and -r * np.exp(s/r) - np.exp(1) * t <= CONE_THRESH))\n",
    "\n",
    "def v_projects_to_bd_Kexp(v):\n",
    "    \"\"\"\n",
    "    Test whether projection of v onto exponential primal cone lies in {(x, 0, z) | x <= 0, z >= 0}.\n",
    "    \"\"\"\n",
    "    return v[0] < 0 and v[1] < 0\n",
    "\n",
    "def proj_exp_cone(v):\n",
    "    \"\"\" \n",
    "    Project v = (r0, s0, t0) onto closure of set {(r, s, t) | s*exp(r/s) - t <= 0}. \n",
    "\n",
    "    If v in primal cone, return v.\n",
    "    If v in polar cone (-v in dual cone), return 0\n",
    "    If r0, s0 < 0, apply analytic projection rule.\n",
    "    Otherwise, project by solving the problem\n",
    "\n",
    "        argmin      |(x, y, z) - (x0, y0, z0)|_2^2\n",
    "        subject to  y exp(x0/y) - z <= 0.\n",
    "\n",
    "    The exponential cone constraint can also be expressed as\n",
    "\n",
    "        x - ylog(z/y) <= 0.\n",
    "        \n",
    "    We can minimize the equivalent unconstrained problem\n",
    "    \n",
    "        min_{v, rho} L(v, rho) = min_{v, rho} |v - v0| + rho g(v),\n",
    "        \n",
    "    where g(v) <= 0 encodes the exponential cone. \n",
    "    \n",
    "    In particular, we search for an optimal rho by bisection; \n",
    "    this generates a series of subproblems wherein we solve \n",
    "    an unconstrained minimization over (r, s, t) for fixed rho. \n",
    "\n",
    "    The bisection search policy is as follows:\n",
    "    \n",
    "        if grad_rho(L) = g(v) < 0, v is feasible, try smaller rho\n",
    "        if grad_rho(L) = g(v) > 0, v infeasible, try larger rho.\n",
    "        \n",
    "    Initialize with interval [rho_lower, rho_upper]. We can\n",
    "    take rho_lower = 0, and initialize rho_upper to be any feasible\n",
    "    value of v.\n",
    "    \"\"\"       \n",
    "    if v_in_Kexp(v):\n",
    "        projv = 1 * v\n",
    "    elif negv_in_Kexp_star(v):\n",
    "        projv = 0 * v\n",
    "    elif v_projects_to_bd_Kexp(v):\n",
    "        projv = np.array([v[0], 0, max(v[2], 0)])\n",
    "    else:\n",
    "        tol = CONE_TOL\n",
    "        projv = 0 * v\n",
    "        lb, ub, projv = exp_rho_bounds(v, projv)\n",
    "        for i in range(EXP_CONE_MAX_ITERS):\n",
    "            rho = 0.5 * (lb + ub)\n",
    "            g, projv = exp_grad_rho(v, projv, rho)\n",
    "            if g > 0:\n",
    "                lb = rho\n",
    "            else:\n",
    "                ub = rho\n",
    "            if ub - lb < tol:\n",
    "                break\n",
    "    return projv\n",
    "\n",
    "def proj_exp_dual_cone(v):\n",
    "    \"\"\" \n",
    "    Project v onto exponential dual cone, via Moreau decomposition\n",
    "    \"\"\"\n",
    "    return v + proj_exp_cone(-v)\n",
    "\n",
    "@dispatch(ExponentialCone, np.ndarray)\n",
    "def project_cone(K, x):\n",
    "    assert x.size == 3 * K.dim, 'input dimension compatible'\n",
    "    return np.hstack([proj_exp_cone(x[3*i:3*(i+1)]) for i in range(K.dim)])\n",
    "\n",
    "@dispatch(ExponentialCone, da.Array)\n",
    "def project_cone(K, x):\n",
    "    assert x.size == 3 * K.dim, 'input dimension compatible'\n",
    "    return da.map_blocks(proj_exp_dual_cone, x.rechunk(3)).rechunk(chunks=x.chunks)\n",
    "\n",
    "@dispatch(ExponentialDualCone, np.ndarray)\n",
    "def project_cone(K, x):\n",
    "    assert x.size == 3 * K.dim, 'input dimension compatible'\n",
    "    return np.hstack([proj_exp_dual_cone(x[3*i:3*(i+1)]) for i in range(K.dim)])\n",
    "\n",
    "@dispatch(ExponentialDualCone, da.Array)\n",
    "def project_cone(K, x):\n",
    "    assert x.size == 3 * K.dim, 'input dimension compatible'\n",
    "    return da.map_blocks(proj_exp_dual_cone, x.rechunk(3)).rechunk(chunks=x.chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CONE_TOL = 1e-8\n",
    "CONE_THRESH = 1e-6 \n",
    "POW_CONE_MAX_ITERS = 20\n",
    "\n",
    "def v_in_Ka(v, a):\n",
    "    return (v[0] >= 0 \n",
    "            and v[1] >= 0 \n",
    "            and CONE_THRESH + v[0]**a * v[1]**(1-a) >= abs(v[2]))\n",
    "def negv_in_Ka_star(v, a):\n",
    "    return (v[0] <= 0 \n",
    "            and v[1] <= 0 \n",
    "            and CONE_THRESH + (-v[0])**a * (-v[1])**(1-a) >= abs(v[2]) * a**a * (1-a)**(1-a))\n",
    "\n",
    "def pow_calc_x(r, xh, rh, a): return max(1e-12, 0.5 * (xh + np.sqrt(xh**2 + 4*a*(rh-r)*r)))\n",
    "def pow_calc_dxdr(x, xh, rh, r, a): return a * (rh - 2*r) / (2*x - xh)\n",
    "def pow_calc_f(x, y, r, a): return pow(x, a) * pow(y, (1-a)) - r\n",
    "def pow_calc_fp(x, y, dxdr, dydr, a): return pow(x, a)*pow(y, (1-a))*(a*dxdr/x + (1-a)*dydr/y) - 1\n",
    "\n",
    "def proj_power(v, a):\n",
    "    assert len(v) == 3\n",
    "#     print v, type(v)\n",
    "#     print a, type(a)\n",
    "    v = np.array(v)\n",
    "    if v_in_Ka(v, a):\n",
    "        projv = v\n",
    "    elif negv_in_Ka_star(v, a):\n",
    "        projv = 0 * v\n",
    "    else:\n",
    "        xx, yy, rr = v[0], v[1], abs(v[2])\n",
    "        xi, yi, ri = 0., 0., rr/2\n",
    "        for i in range(POW_CONE_MAX_ITERS):\n",
    "            xi = pow_calc_x(ri, xx, rr, a)\n",
    "            yi = pow_calc_x(ri, yy, rr, 1-a)\n",
    "            fi = pow_calc_f(xi, yi, ri, a)\n",
    "            if abs(fi) < CONE_TOL:\n",
    "                break\n",
    "            dxdr = pow_calc_dxdr(xi, xx, rr, ri, a)\n",
    "            dydr = pow_calc_dxdr(yi, yy, rr, ri, 1-a)\n",
    "            fp = pow_calc_fp(xi, yi, dxdr, dydr, a)\n",
    "            ri = min(rr, max(ri - fi/fp, 0))\n",
    "        projv = np.array([xi, yi, -ri if v[2] < 0 else ri])\n",
    "    return projv\n",
    "\n",
    "def proj_power_dual(v, a):\n",
    "    v = np.array(v)\n",
    "    return v + proj_power(-v, a)\n",
    "\n",
    "def proj_pow_cone(v, a):\n",
    "    # a > 0: primal cone  \n",
    "    # a <= 0: dual cone via Moreau decomposition x = prox_K(x) + prox_Kstar(-x)   \n",
    "    return proj_power(v, a) if a > 0 else proj_power_dual(v, -a)\n",
    "\n",
    "# {(x,y,z) | x^a * y^(1-a) >= |z|, x>=0, y>=0}\n",
    "@dispatch(PowerCone, np.ndarray)\n",
    "def project_cone(K, x):\n",
    "    assert x.size == 3 * K.dim, 'input dimension compatible'\n",
    "    return np.hstack([proj_pow_cone(x[3*i:3*(i+1)], K.powers[i]) for i in range(K.dim)])\n",
    "\n",
    "@dispatch(PowerCone, da.Array)\n",
    "def project_cone(K, x):\n",
    "    assert x.shape[0] == x.size and x.size == 3 * K.dim, 'input dimension compatible'\n",
    "    x3 = x.rechunk(chunks=3)\n",
    "    dsk = dict()\n",
    "    token = 'project-power-cone-' + dask.base.tokenize(K, x)\n",
    "    for i in range(x3.numblocks[0]):\n",
    "        dsk[(token, i)] = (proj_pow_cone, (x3.name, i), K.powers[i])\n",
    "    projx = da.Array(dask.sharedict.merge(dsk, x3.dask), token, shape=x.shape, chunks=x3.chunks, dtype=x.dtype)\n",
    "    return projx.rechunk(chunks=x.chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_cone(K, x):\n",
    "    tol_cone = 10**isinstance(K, PositiveSemidefiniteCone)\n",
    "    xp = project_cone(K, x)\n",
    "    xd = da.from_array(x, chunks=x.size/2)\n",
    "    xdp = project_cone(K, xd).compute()\n",
    "    norm, tol = np.linalg.norm(xp - xdp), 1e-15 * (1 + x.size**0.5) * tol_cone\n",
    "    assert norm < tol, '|proj_npy - proj_dask| < tol: {} < {}'.format(norm, tol)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = 10\n",
    "K, x = ZeroCone(m), np.random.normal(0, 1, m)\n",
    "Kstar = ZeroDualCone(m)\n",
    "assert test_cone(K, x)\n",
    "assert test_cone(Kstar, x)\n",
    "assert sum(project_cone(K, x)) == 0\n",
    "assert sum(project_cone(Kstar, x) - x) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = 10\n",
    "K, x = NonnegativeCone(m), np.random.normal(0, 1, m)\n",
    "Kstar = NonnegativeDualCone(m)\n",
    "assert test_cone(K, x)\n",
    "assert test_cone(Kstar, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = 10\n",
    "K, x = SecondOrderCone(m), np.random.normal(0, 1, m)\n",
    "Kstar = SecondOrderDualCone(m)\n",
    "# cone behavior\n",
    "xp = project_cone(K, x)\n",
    "xp[0] = 2 * xp[0]\n",
    "xpp = project_cone(K, xp)\n",
    "assert xpp[0] == xp[0]\n",
    "assert sum(xpp[1:] - xp[1:]) == 0\n",
    "xp[0] = -1.05 * xp[0]\n",
    "xpp = project_cone(K, xp)\n",
    "assert sum(xpp) == 0\n",
    "\n",
    "# dask matches numpy\n",
    "assert test_cone(K, x)\n",
    "assert test_cone(Kstar, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 10\n",
    "mc = 5\n",
    "K = PositiveSemidefiniteCone(m)\n",
    "Kstar = PositiveSemidefiniteDualCone(m)\n",
    "X = np.random.random((m, m))\n",
    "X = 1 + X.T.dot(X)\n",
    "x = X.reshape(-1)\n",
    "projx = project_cone(K, x)\n",
    "project_cone(K, da.from_array(x, chunks=mc)).compute() - projx\n",
    "assert test_cone(K, x)\n",
    "assert test_cone(Kstar, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# primal exp cone\n",
    "yt = 2.\n",
    "xt = 3.2\n",
    "zt = 1.05 * yt * np.exp(xt/yt)\n",
    "vt = np.array([xt, yt, zt])\n",
    "assert v_in_Kexp(vt)\n",
    "assert sum(vt - proj_exp_cone(vt)) == 0\n",
    "vt = np.array([-2, 0, 2])\n",
    "assert v_in_Kexp(vt)\n",
    "assert sum(vt - proj_exp_cone(vt)) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dual exp cone\n",
    "u = -2\n",
    "w = 2.5\n",
    "v = 1.05 * u * (1 * np.log(-w/u))\n",
    "vt = -np.array([u, v, w])\n",
    "assert negv_in_Kexp_star(vt)\n",
    "assert sum(proj_exp_cone(vt)) == 0\n",
    "vt = -np.array([0, 1, 0.5])\n",
    "assert negv_in_Kexp_star(vt)\n",
    "assert sum(proj_exp_cone(vt)) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# project to bd(Kexp)\n",
    "vt = np.array([0, 0, 0.5])\n",
    "assert sum(proj_exp_cone(vt) - vt) == 0\n",
    "vt = np.array([-1, -1, 0.5])\n",
    "vproj = np.array([-1, 0, 0.5])\n",
    "assert sum(proj_exp_cone(vt) - vproj) == 0\n",
    "vt = np.array([-1, -1, -0.5])\n",
    "vproj = np.array([-1, 0, 0])\n",
    "assert sum(proj_exp_cone(vt) - vproj) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remaining projections\n",
    "yt = 2.\n",
    "xt = 3.2\n",
    "zt = 1.01 * yt * np.exp(xt/yt)\n",
    "vt = np.array([xt, yt, 0.95 * zt])\n",
    "vtp = proj_exp_cone(vt)\n",
    "assert not v_in_Kexp(vt) \n",
    "assert v_in_Kexp(vtp)\n",
    "vt = np.array([2 * xt, 2 * yt, zt])\n",
    "vtp = proj_exp_cone(vt)\n",
    "assert not v_in_Kexp(vt) \n",
    "assert v_in_Kexp(vtp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 10\n",
    "mc = 5\n",
    "K = ExponentialCone(m)\n",
    "Kstar = ExponentialDualCone(m)\n",
    "x = np.random.uniform(1, 10, 3 * m)\n",
    "projx = project_cone(K, x)\n",
    "PX = projx.reshape((-1, 3))\n",
    "assert all([v_in_Kexp(PX[i, :]) for i in range(m)])\n",
    "assert test_cone(K, x)\n",
    "assert test_cone(Kstar, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 1\n",
    "mc = 5\n",
    "p = np.random.uniform(-1, 1, m)\n",
    "K = PowerCone(p)\n",
    "Kstar = PowerDualCone(p)\n",
    "x = np.random.uniform(1, 10, 3 * m)\n",
    "projx = project_cone(K, x)\n",
    "PX = projx.reshape((-1, 3))\n",
    "def in_cone(v, p): return v_in_Ka(v, p) if p > 0 else negv_in_Ka_star(-v, -p)\n",
    "assert all([in_cone(PX[i, :], p[i]) for i in range(m)])\n",
    "assert test_cone(K, x)\n",
    "assert test_cone(Kstar, x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
