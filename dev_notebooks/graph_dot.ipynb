{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import multipledispatch\n",
    "import functools\n",
    "import numpy as np\n",
    "import operator\n",
    "import dask\n",
    "import dask\n",
    "import dask.array as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "PROJECT_PATH = os.path.realpath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(PROJECT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scs_dask.linalg.linear_operator as linop\n",
    "\n",
    "namespace_atoms = dict()\n",
    "dispatch = functools.partial(multipledispatch.dispatch, namespace=namespace_atoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@dispatch(da.Array, str, str)\n",
    "def graph_dot(array, input_key, output_key, transpose=False, **options):\n",
    "    r\"\"\" Build dask graph storing as output a linear operator applied to input.\n",
    "\n",
    "    Args:\n",
    "        array (:obj:`da.Array`): Matrix\n",
    "        input_key (:obj:`str`): Key, in some dask graph, of an input\n",
    "            vector assumed to be compatibly sized and chunked with\n",
    "            the array.\n",
    "        output_key (:obj:`str`): Key of an output vector.\n",
    "        transpose (:obj:`bool`, optional): If ``True``, form output as\n",
    "            :math:`w = A^Tz`; by default form :math:`y = Ax`.\n",
    "\n",
    "    Returns:\n",
    "        :obj:`dask.sharedict.Sharedict`: dask graph of matrix-vector\n",
    "        product assigned to output vector.\n",
    "    \"\"\"\n",
    "    if transpose:\n",
    "        idx_out, idx_arr, idx_in = 'j', 'ij', 'i'\n",
    "        transform = da.transpose\n",
    "    else:\n",
    "        idx_out, idx_arr, idx_in = 'i', 'ij', 'j'\n",
    "        transform = None\n",
    "    blks_in = (array.numblocks[1 - int(transpose)],)\n",
    "\n",
    "    dsk_out = da.core.top(\n",
    "            da.core.dotmany,\n",
    "            output_key, idx_out,\n",
    "            array.name, idx_arr,\n",
    "            input_key, idx_in,\n",
    "            leftfunc=transform,\n",
    "            numblocks={array.name: array.numblocks, input_key: blks_in})\n",
    "    dsk = dask.sharedict.merge(array.dask)\n",
    "    dsk.update_with_key(dsk_out, output_key)\n",
    "    return dsk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@dispatch(linop.DLODense, str, str)\n",
    "def graph_dot(dense_op, input_key, output_key, transpose=False, **options):\n",
    "    \"\"\" Implementation of :func:`graph_dot` for a dense linear operator.\n",
    "    \"\"\"\n",
    "    return graph_dot(dense_op.data, input_key, output_key, transpose=transpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@dispatch(linop.DLODiagonal, str, str)\n",
    "def graph_dot(diag_op, input_key, output_key, **options):\n",
    "    \"\"\" Implementation of :func:`graph_dot` for a diagonal linear operator.\n",
    "    \"\"\"\n",
    "    vec = diag_op.data\n",
    "    dsk_out = da.core.top(\n",
    "            operator.mul, output_key, 'i', vec.name, 'i', input_key, 'i',\n",
    "            numblocks={vec.name: vec.numblocks, input_key: vec.numblocks})\n",
    "    dsk = dask.sharedict.merge(diag_op.dask)\n",
    "    dsk.update_with_key(dsk_out, output_key)\n",
    "    return dsk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@dispatch(linop.DLOGram, str, str)\n",
    "def graph_dot(gram_op, input_key, output_key, **options):\n",
    "    \"\"\" Implementation of :func:`graph_dot` for a gram operator.\n",
    "    \"\"\"\n",
    "    mid_key = gram_op.name + '-gramA-' + input_key\n",
    "    dsk_Ax = graph_dot(\n",
    "            gram_op.data, input_key, mid_key, transpose=gram_op.transpose)\n",
    "    dsk_AAx = graph_dot(\n",
    "            gram_op.data, mid_key, output_key, transpose=(not gram_op.transpose))\n",
    "    return dask.sharedict.merge(dsk_Ax, dsk_AAx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dispatch(linop.DLORegularizedGram, str, str)\n",
    "def graph_dot(gram_op, input_key, output_key, **options):\n",
    "    \"\"\" Implementation of :func:`graph_dot` for a regularized operator.\n",
    "    \"\"\"\n",
    "    mid_key = gram_op.name + '-gramAA-' + input_key\n",
    "    blocks = (gram_op.numblocks[0],)\n",
    "    def wrap_gram(data):\n",
    "        return data if isinstance(data, linop.DLOGram) else linop.DLOGram(data)\n",
    "    def add_regularization(AAxi, xi):\n",
    "        return AAxi + gram_op.regularization * xi\n",
    "\n",
    "    dsk_AAx = graph_dot(wrap_gram(gram_op.data), input_key, mid_key)\n",
    "    dsk_IAAx = da.core.top(\n",
    "            add_regularization, output_key, 'i', mid_key, 'i', input_key, 'i',\n",
    "            numblocks={mid_key: blocks, input_key: blocks})\n",
    "    dsk = dask.sharedict.merge(dsk_AAx)\n",
    "    dsk.update_with_key(dsk_IAAx, output_key)\n",
    "    return dsk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = da.random.random((100, 50), chunks=10)\n",
    "B = da.random.random((50, 100), chunks=10)\n",
    "x = da.random.random(50, chunks=10)\n",
    "y = da.random.random(100, chunks=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsk_Ax = dask.sharedict.merge(graph_dot(A, x.name, 'Ax'), x.dask)\n",
    "dsk_Ax = dask.sharedict.merge(dsk_Ax, x.dask)\n",
    "Ax = da.Array(dsk_Ax, 'Ax', shape=(A.shape[0],), chunks=(A.chunks[0],), dtype=A.dtype)\n",
    "(diff,) = dask.compute(Ax - A.dot(x))\n",
    "assert np.linalg.norm(diff) < 1e-15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsk_ATy = graph_dot(A, y.name, 'ATy', transpose=True)\n",
    "dsk_ATy = dask.sharedict.merge(dsk_ATy, y.dask)\n",
    "ATy = da.Array(dsk_ATy, 'ATy', shape=(A.shape[1],), chunks=(A.chunks[1],), dtype=A.dtype)\n",
    "(diff, ATy) = dask.compute(ATy - da.transpose(A).dot(y), ATy)\n",
    "assert np.linalg.norm(diff) < 1e-15 * (1 + np.linalg.norm(ATy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsk_Ax = graph_dot(linop.DLODense(A), x.name, 'Ax')\n",
    "dsk_Ax = dask.sharedict.merge(dsk_Ax, x.dask)\n",
    "Ax = da.Array(dsk_Ax, 'Ax', shape=(A.shape[0],), chunks=(A.chunks[0],), dtype=A.dtype)\n",
    "(diff,) = dask.compute(Ax - A.dot(x))\n",
    "assert np.linalg.norm(diff) < 1e-15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DD = da.random.random(x.shape, chunks=x.chunks)\n",
    "dsk_Dx = graph_dot(linop.DLODiagonal(DD), x.name, 'Dx')\n",
    "dsk_Dx = dask.sharedict.merge(dsk_Dx, x.dask)\n",
    "Dx = da.Array(dsk_Dx, 'Dx', shape=x.shape, chunks=x.chunks, dtype=x.dtype)\n",
    "(diff,) = dask.compute(Dx - DD * x)\n",
    "assert np.linalg.norm(diff) < 1e-15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dsk_AAx for A'A\n",
    "dsk_AAx = graph_dot(linop.DLOGram(A, name='ATA'), x.name, 'AAx')\n",
    "dsk_AAx = dask.sharedict.merge(dsk_AAx, x.dask)\n",
    "AAx = da.Array(dsk_AAx, 'AAx', shape=(A.shape[1],), chunks=(A.chunks[1],), dtype=A.dtype)\n",
    "diff = AAx - da.transpose(A).dot(A.dot(x))\n",
    "(diff, AAx) = dask.compute(diff, AAx)\n",
    "assert np.linalg.norm(diff) < 1e-15 * (1 + np.linalg.norm(AAx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dsk_BBx for BB'\n",
    "dsk_BBx = graph_dot(linop.DLOGram(B, name='BBT'), x.name, 'BBx')\n",
    "dsk_AAx = dask.sharedict.merge(dsk_BBx, x.dask)\n",
    "BBx = da.Array(dsk_BBx, 'BBx', shape=x.shape, chunks=x.chunks, dtype=x.dtype)\n",
    "diff = BBx - B.dot(da.transpose(B).dot(x))\n",
    "(diff, BBx) = dask.compute(diff, BBx)\n",
    "assert np.linalg.norm(diff) < 1e-15 * (1 + np.linalg.norm(BBx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mu = 1 + np.random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dsk_IAAx for mu * I + A'A\n",
    "muIAA = linop.DLORegularizedGram(A, regularization=mu)\n",
    "dsk_muIAAx = graph_dot(muIAA, x.name, 'muIAAx')\n",
    "dsk_muIAAx = dask.sharedict.merge(dsk_muIAAx, x.dask)\n",
    "muIAAx = da.Array(dsk_muIAAx, 'muIAAx', shape=(A.shape[1],), chunks=(A.chunks[1],), dtype=A.dtype)\n",
    "diff = muIAAx - (mu * x + da.transpose(A).dot(A.dot(x)))\n",
    "(diff, muIAAx) = dask.compute(diff, muIAAx)\n",
    "assert np.linalg.norm(diff) < 1e-15 * (1 + np.linalg.norm(muIAAx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dsk_IBBx for mu * I + BB')\n",
    "muIBB = linop.DLORegularizedGram(B, regularization=mu)\n",
    "dsk_muIBBx = graph_dot(muIBB, x.name, 'muIBBx')\n",
    "dsk_muIBBx = dask.sharedict.merge(dsk_muIBBx, x.dask)\n",
    "muIBBx = da.Array(dsk_muIBBx, 'muIBBx', shape=(B.shape[0],), chunks=(B.chunks[0],), dtype=B.dtype)\n",
    "diff = muIBBx - (mu * x + B.dot(da.transpose(B).dot(x)))\n",
    "(diff, muIBBx) = dask.compute(diff, muIBBx)\n",
    "assert np.linalg.norm(diff) < 1e-15 * (1 + np.linalg.norm(muIBBx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
