{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import operator\n",
    "import functools\n",
    "import dask \n",
    "import dask.array as da\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REPEAT_OLD = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## warmstart vector x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cg_init_dsk(A, b, state0, x_init=None):\n",
    "    x0, r0, p0 = map(lambda nm: nm + '-' + state0, ('x', 'r', 'p'))\n",
    "    scal_x = float(x_init is not None)\n",
    "    vec_x = b if x_init is None else x_init\n",
    "    def init_x(x_or_b): \n",
    "        return scal_x * x_or_b\n",
    "    def init_p(ri): return 1 * ri\n",
    "    dsk = dict()\n",
    "    vblocks, hblocks = A.numblocks\n",
    "    for i in range(vblocks):\n",
    "        dsk[(x0, i)] = (init_x, (vec_x.name, i))\n",
    "        dsk[(r0, i)] = (operator.sub,\n",
    "                (da.core.dotmany, [(A.name, i, j) for j in range(hblocks)], [(x0, j) for j in range(hblocks)]),\n",
    "                (b.name, i))\n",
    "        dsk[(p0, i)] = (init_p, (r0, i))\n",
    "    return dsk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cg_calcs_proto(shape, chunks, dtype, dsk, key):\n",
    "    x = da.Array(dsk, 'x-' + key, shape=shape, chunks=chunks, dtype=dtype)\n",
    "    r = da.Array(dsk, 'r-' + key, shape=shape, chunks=chunks, dtype=dtype)\n",
    "    p = da.Array(dsk, 'p-' + key, shape=shape, chunks=chunks, dtype=dtype)\n",
    "    (x, r, p) = dask.persist(x, r, p, optimize_graph=False, traverse=False)\n",
    "    (res,) = dask.compute(da.linalg.norm(r))\n",
    "    return x, r, p, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, mc = 1000, 100\n",
    "Arand = np.random.random((m, m))\n",
    "Arand = Arand.T.dot(Arand)\n",
    "brand, xrand = np.random.random(m), np.random.random(m)\n",
    "AA = da.from_array(Arand, chunks=mc, name='A')\n",
    "bb = da.from_array(brand, chunks=mc, name='b')\n",
    "xx = da.from_array(xrand, chunks=mc, name='x0')\n",
    "cg_calcs = functools.partial(cg_calcs_proto, bb.shape, bb.chunks, bb.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsk = dask.sharedict.merge(AA.dask, bb.dask, cg_init_dsk(AA, bb, 'cg-iter0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, r, p, res = cg_calcs(dsk, 'cg-iter0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsk = dask.sharedict.merge(AA.dask, bb.dask, xx.dask, cg_init_dsk(AA, bb, 'cg-iter0', x_init=xx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, r, p, res = cg_calcs(dsk, 'cg-iter0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsk = cg_init_dsk(AA, bb, 'cg-iter0', x_init=xx)\n",
    "dasks = [AA.dask, bb.dask, dsk]\n",
    "dasks += [xx.dask]\n",
    "dsk = dask.sharedict.merge(*dasks)\n",
    "x, r, p, res = cg_calcs(dsk, 'cg-iter0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## linear operator A "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def graph_dot(A, key_in, key_out):\n",
    "    \"\"\" For A <: dask.array.Array \"\"\"\n",
    "    vblocks, hblocks = A.numblocks\n",
    "    dsk = dict()\n",
    "    for i in range(vblocks):\n",
    "        dsk[(key_out, i)] = (\n",
    "                da.core.dotmany,\n",
    "                [(A.name, i, j) for j in range(hblocks)],\n",
    "                [(key_in, j) for j in range(hblocks)])\n",
    "    return dsk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def graph_gemv(key_alpha, A, key_x, key_beta, key_y, key_out):\n",
    "    \"\"\" For A <: dask.array.Array \"\"\"\n",
    "    vblocks, hblocks = A.numblocks\n",
    "    key_Ax = A.name + '-mul-' + key_x\n",
    "    dsk = dict()\n",
    "    def gemv(alpha, Axi, beta, yi): return alpha * Axi + beta * yi\n",
    "    for i in range(vblocks):\n",
    "        dsk[(key_out, i)] = (gemv, key_alpha, (key_Ax, i), key_beta, (key_y, i))\n",
    "    dsk.update(graph_dot(A, key_x, key_Ax))\n",
    "    return dsk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cg_init_graph1(A, b, state0, x_init=None):\n",
    "    x0, r0, p0 = map(lambda nm: nm + '-' + state0, ('x', 'r', 'p'))\n",
    "    scal_x = float(x_init is not None)\n",
    "    vec_x = b if x_init is None else x_init\n",
    "    def init_x(x_or_b): return scal_x * x_or_b\n",
    "    def init_p(ri): return 1 * ri\n",
    "    dsk = dict()\n",
    "    vblocks, hblocks = A.numblocks\n",
    "    dsk_Ax = graph_dot(A, x0, 'Ax')\n",
    "    for i in range(vblocks):\n",
    "        dsk[(x0, i)] = (init_x, (vec_x.name, i))\n",
    "        dsk[(p0, i)] = (init_p, (r0, i))\n",
    "        dsk[(r0, i)] = (operator.sub, dsk_Ax[('Ax', i)], (b.name, i))\n",
    "    return dsk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsk = cg_init_graph1(AA, bb, 'cg-iter0', x_init=xx)\n",
    "dasks = [AA.dask, bb.dask, dsk]\n",
    "dasks += [xx.dask]\n",
    "dsk = dask.sharedict.merge(*dasks)\n",
    "x, r, p, res = cg_calcs(dsk, 'cg-iter0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cg_init_graph2(A, b, state0, x_init=None):\n",
    "    x0, r0, p0 = map(lambda nm: nm + '-' + state0, ('x', 'r', 'p'))\n",
    "    scal_x = float(x_init is not None)\n",
    "    vec_x = b if x_init is None else x_init\n",
    "    def init_x(x_or_b): return scal_x * x_or_b\n",
    "    def init_p(ri): return 1 * ri\n",
    "    dsk = dict()\n",
    "    vblocks, hblocks = A.numblocks\n",
    "    for i in range(vblocks):\n",
    "        dsk[(x0, i)] = (init_x, (vec_x.name, i))\n",
    "        dsk[(p0, i)] = (init_p, (r0, i))\n",
    "    dsk.update(graph_gemv(1, A, x0, -1, b.name, r0))\n",
    "    return dsk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dsk = cg_init_graph2(AA, bb, 'cg-iter0', x_init=xx)\n",
    "dasks = [AA.dask, bb.dask, dsk]\n",
    "dasks += [xx.dask]\n",
    "dsk = dask.sharedict.merge(*dasks)\n",
    "x, r, p, res = cg_calcs(dsk, 'cg-iter0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cg_iterate_graph1(A, state0, state1):\n",
    "    Ap, pAp = 'Ap-' + state0, 'pAp-' + state0\n",
    "    x0, r0, p0, gamma0 = map(lambda nm: nm + '-' + state0, ('x', 'r', 'p', 'gamma'))\n",
    "    x1, r1, p1, gamma1 = map(lambda nm: nm + '-' + state1, ('x', 'r', 'p', 'gamma'))\n",
    "    def update_x(x, gamma, pAp, p): return x + (gamma / pAp) * p\n",
    "    def update_r(r, gamma, pAp, Ap): return r - (gamma / pAp) * Ap\n",
    "    def update_p(p, gamma, gamma_next, r): return r + (gamma_next / gamma) * p\n",
    "    dsk = dict()\n",
    "    vblocks, hblocks = A.numblocks\n",
    "    dsk.update(graph_dot(A, p0, Ap))\n",
    "    dsk[gamma0] = (da.core.dotmany, [(r0, i) for i in range(vblocks)], [(r0, i) for i in range(vblocks)])\n",
    "    dsk[pAp] = (da.core.dotmany, [(p0, i) for i in range(vblocks)], [(Ap, i) for i in range(vblocks)])\n",
    "    for i in range(vblocks):\n",
    "        dsk[(x1, i)] = (update_x, (x0, i), gamma0, pAp, (p0, i))\n",
    "        dsk[(r1, i)] = (update_r, (r0, i), gamma0, pAp, (Ap, i))\n",
    "        dsk[(p1, i)] = (update_p, (p0, i), gamma0, gamma1, (r1, i))\n",
    "    dsk[gamma1] = (da.core.dotmany, [(r1, i) for i in range(vblocks)], [(r1, i) for i in range(vblocks)])\n",
    "    return dsk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dsk = cg_iterate_graph1(AA, 'cg-iter0', 'cg-iter1')\n",
    "dasks = [AA.dask, x.dask, r.dask, p.dask, dsk]\n",
    "dsk = dask.sharedict.merge(*dasks)\n",
    "x, r, p, res = cg_calcs(dsk, 'cg-iter1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preconditioned CG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cg_init_graph3(A, b, state0, x_init=None):\n",
    "    M = A.preconditioner\n",
    "    A = A.linear_operator\n",
    "    x0, r0, p0 = map(lambda nm: nm + '-' + state0, ('x', 'r', 'p'))\n",
    "    scal_x = float(x_init is not None)\n",
    "    vec_x = b if x_init is None else x_init\n",
    "    def init_x(x_or_b): return scal_x * x_or_b\n",
    "    def init_p(ri): return 1 * ri\n",
    "    dsk = dict()\n",
    "    vblocks, hblocks = A.numblocks\n",
    "    for i in range(vblocks):\n",
    "        dsk[(x0, i)] = (init_x, (vec_x.name, i))\n",
    "        dsk[(p0, i)] = (init_p, (r0, i))\n",
    "    dsk.update(graph_gemv(1, A, x0, -1, b.name, r0))\n",
    "    dsk.update(graph_dot(M, r0, p0))\n",
    "    return dsk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_blocks(nm, blocks=0): return [(nm, i) for i in range(blocks)]\n",
    "def dict_blocks(dictionary, nm, blocks=0): return [dictionary[(nm, i)] for i in range(blocks)]\n",
    "    \n",
    "def cg_iterate_graph2(A, state0, state1):\n",
    "    M = A.preconditioner\n",
    "    A = A.linear_operator\n",
    "    Ap, pAp = 'Ap-' + state0, 'pAp-' + state0\n",
    "    x0, r0, p0, rMr0 = map(lambda nm: nm + '-' + state0, ('x', 'r', 'p', 'rMr'))\n",
    "    x1, r1, p1, rMr1 = map(lambda nm: nm + '-' + state1, ('x', 'r', 'p', 'rMr'))\n",
    "    def update_x(x, rMr, pAp, p): return x + (rMr / pAp) * p\n",
    "    def update_r(r, rMr, pAp, Ap): return r - (rMr / pAp) * Ap\n",
    "    def update_p(p, rMr, rMr_next, Mr): return Mr + (rMr_next / rMr) * p\n",
    "    dsk = dict()    \n",
    "    vblocks, hblocks = A.numblocks\n",
    "    get_blocks = functools.partial(list_blocks, blocks=vblocks)\n",
    "    get_blocks_d = functools.partial(dict_blocks, blocks=vblocks)\n",
    "    dsk.update(graph_dot(A, p0, Ap))\n",
    "    dsk_Mr0 = graph_dot(M, r0, 'Mr0')\n",
    "    dsk_Mr1 = graph_dot(M, r1, 'Mr1')\n",
    "    dsk[rMr0] = (da.core.dotmany, get_blocks(r0), get_blocks_d(dsk_Mr0, 'Mr0'))\n",
    "    dsk[rMr1] = (da.core.dotmany, get_blocks(r1), get_blocks_d(dsk_Mr1, 'Mr1'))\n",
    "    dsk[pAp] = (da.core.dotmany, get_blocks(p0), get_blocks(Ap))\n",
    "    for i in range(vblocks):\n",
    "        dsk[(x1, i)] = (update_x, (x0, i), rMr0, pAp, (p0, i))\n",
    "        dsk[(r1, i)] = (update_r, (r0, i), rMr0, pAp, (Ap, i))\n",
    "        dsk[(p1, i)] = (update_p, (p0, i), rMr0, rMr1, dsk_Mr1[('Mr1', i)])\n",
    "    return dsk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "MM = da.from_array(np.diag(1. / np.diag(Arand)), chunks=AA.chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrecondLinop:\n",
    "    def __init__(self, linop, preconditioner):\n",
    "        self.linear_operator = linop\n",
    "        self.preconditioner = preconditioner\n",
    "\n",
    "P = PrecondLinop(AA, MM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsk = cg_init_graph3(P, bb, 'cg-iter0', x_init=xx)\n",
    "dasks = [AA.dask, MM.dask, bb.dask, dsk]\n",
    "dasks += [xx.dask]\n",
    "dsk = dask.sharedict.merge(*dasks)\n",
    "x, r, p, res = cg_calcs(dsk, 'cg-iter0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsk = cg_iterate_graph2(P, 'cg-iter0', 'cg-iter1')\n",
    "dasks = [AA.dask, MM.dask, x.dask, r.dask, p.dask, dsk]\n",
    "dsk = dask.sharedict.merge(*dasks)\n",
    "x, r, p, res = cg_calcs(dsk, 'cg-iter1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_options(graph_iters=1, verbose=0, print_iters=0, time_iters=0):\n",
    "    graph_iters = max(1, int(graph_iters))\n",
    "    time_iters = max(0, int(time_iters))\n",
    "    if int(print_iters) < 1 and verbose > 0:\n",
    "        print_iters = max(0, max(int(print_iters), int(10**(3 - verbose))))\n",
    "    if print_iters > 0:\n",
    "        print_iters = max(print_iters, graph_iters)\n",
    "    return graph_iters, print_iters, time_iters\n",
    "\n",
    "def cg_graph_dense(A, M, b, x_init=None, tol=1e-5, maxiter=500, **options):\n",
    "    P = PrecondLinop(A, M)\n",
    "    cg_calcs = functools.partial(cg_calcs_proto, b.shape, b.chunks, b.dtype)\n",
    "    graph_iters, print_iters, time_iters = iter_options(**options)\n",
    "    key_init = 'cg-iter0'\n",
    "    dsk = dask.sharedict.merge(A.dask, M.dask, b.dask, cg_init_graph3(P, b, key_init, x_init=x_init))\n",
    "    x, r, p, res = cg_calcs(dsk, key_init)\n",
    "    if time_iters > 0:\n",
    "        start = time.time()\n",
    "    dsk = dict()\n",
    "    for i in range(1, maxiter + 1):\n",
    "        key0 = 'cg-iter{}'.format(i - 1)\n",
    "        key1 = 'cg-iter{}'.format(i)\n",
    "        calculate = bool(i % graph_iters == 0)\n",
    "        dsk.update(cg_iterate_graph2(P, key0, key1))\n",
    "        if calculate:\n",
    "            dsk = dask.sharedict.merge(A.dask, M.dask, x.dask, r.dask, p.dask, dsk)\n",
    "            x, r, p, res = cg_calcs(dsk, key1)\n",
    "            dsk = dict()\n",
    "            if print_iters > 0 and i % print_iters == 0:\n",
    "                print '\\t\\t\\t{}: residual = {:.1e}'.format(i, res)\n",
    "            if res < tol:\n",
    "                break\n",
    "        if time_iters > 0 and i % time_iters == 0:\n",
    "            print '{}: {:.1e} seconds'.format(i, time.time() - start)\n",
    "            start = time.time()\n",
    "    if i == maxiter:\n",
    "        dsk = dask.sharedict.merge(A.dask, M.dask, x.dask, r.dask, p.dask, dsk)\n",
    "        x, _, _, res = cg_calcs(dsk, key1)\n",
    "    return x, res, i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagA = 0.5 + np.sqrt(range(1, m + 1))\n",
    "Acg = (\n",
    "    np.eye(m, m, -1) \n",
    "    + np.eye(m, m, 1) \n",
    "    + np.eye(m, m, -m/10)\n",
    "    + np.eye(m, m, m/10)\n",
    "    + np.diag(diagA))\n",
    "Mcg = np.diag(1. / diagA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "AA = da.from_array(Acg, chunks=mc)\n",
    "MM = da.from_array(Mcg, chunks=mc)\n",
    "II = da.from_array(np.eye(m), chunks=mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REPEAT_OLD:\n",
    "    start = time.time()\n",
    "    x, res, iters = cg_graph_dense(AA, MM, bb, verbose=2, time_iters=5, graph_iters=10)\n",
    "    print \"TOTAL\", time.time() - start, iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REPEAT_OLD:\n",
    "    start = time.time()\n",
    "    x, res, iters = cg_graph_dense(AA, II, bb, verbose=2, time_iters=5, graph_iters=10)\n",
    "    print \"TOTAL\", time.time() - start, iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Baris/Documents/Thesis/modules/scs-dask\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "PROJECT_PATH = os.path.realpath(os.path.join(os.getcwd(), '..'))\n",
    "print PROJECT_PATH\n",
    "sys.path.append(PROJECT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scs_dask.linalg import linear_operator as linop\n",
    "from scs_dask.linalg import atoms2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multipledispatch\n",
    "\n",
    "namespace_atoms2 = dict()\n",
    "dispatch = functools.partial(multipledispatch.dispatch, namespace=namespace_atoms2)\n",
    "\n",
    "@dispatch(da.Array, str, str)\n",
    "def graph_dot(array, input_key, output_key, transpose=False, **options):\n",
    "    \"\"\" TODO: docstring \"\"\"\n",
    "    matvec = functools.partial(da.core.dotmany, leftfunc=np.transpose) if transpose else da.core.dotmany\n",
    "    def Aij(i, j): return (array.name, j, i) if transpose else (array.name, i, j)\n",
    "    blocks_out, blocks_in = array.numblocks[::-1] if transpose else array.numblocks\n",
    "    dsk = dict()\n",
    "    for i in range(blocks_out):\n",
    "        dsk[(output_key, i)] = (matvec,\n",
    "                             [Aij(i, j) for j in range(blocks_in)],\n",
    "                             [(input_key, j) for j in range(blocks_in)])\n",
    "    return dsk\n",
    "\n",
    "@dispatch(linop.DLODense, str, str)\n",
    "def graph_dot(dense_op, input_key, output_key, transpose=False, **options):\n",
    "    \"\"\" Implementation of :func:`graph_dot` for a dense linear operator.\n",
    "    \"\"\"\n",
    "    return graph_dot(dense_op.data, input_key, output_key, transpose=transpose)\n",
    "\n",
    "@dispatch(linop.DLODiagonal, str, str)\n",
    "def graph_dot(diag_op, input_key, output_key, **options):\n",
    "    \"\"\" Implementation of :func:`graph_dot` for a diagonal linear operator.\n",
    "    \"\"\"\n",
    "    vec = diag_op.data\n",
    "    dsk = dict()\n",
    "    for i in range(vec.numblocks[0]):\n",
    "        dsk[(output_key, i)] = (operator.mul, (vec.name, i), (input_key, i))\n",
    "    return dsk\n",
    "\n",
    "@dispatch(linop.DLOGram, str, str)\n",
    "def graph_dot(gram_op, input_key, output_key, **options):\n",
    "    \"\"\" Implementation of :func:`graph_dot` for a gram operator.\n",
    "    \"\"\"\n",
    "    mid_key = gram_op.name + '-gramA-' + input_key\n",
    "    dsk = graph_dot(gram_op.data, input_key, mid_key, transpose=gram_op.transpose)\n",
    "    dsk.update(graph_dot(gram_op.data, mid_key, output_key, transpose=(not gram_op.transpose)))\n",
    "    return dsk\n",
    "\n",
    "@dispatch(linop.DLORegularizedGram, str, str)\n",
    "def graph_dot(gram_op, input_key, output_key, **options):\n",
    "    \"\"\" Implementation of :func:`graph_dot` for a regularized operator.\n",
    "    \"\"\"\n",
    "    mid_key = gram_op.name + '-gramAA-' + input_key\n",
    "    def wrap_gram(data):\n",
    "        return data if isinstance(data, linop.DLOGram) else linop.DLOGram(data, transpose=gram_op.transpose)\n",
    "    def add_regularization(AAxi, xi):\n",
    "        return AAxi + gram_op.regularization * xi\n",
    "\n",
    "    dsk = graph_dot(wrap_gram(gram_op.data), input_key, mid_key)\n",
    "    for i in range(gram_op.numblocks[0]):\n",
    "        dsk[(output_key, i)] = (add_regularization, (mid_key, i), (input_key, i))\n",
    "    return dsk\n",
    "\n",
    "\n",
    "def list_blocks(nm, blocks=0): return [(nm, i) for i in range(blocks)]\n",
    "def dict_blocks(dictionary, nm, blocks=0): return [dictionary[(nm, i)] for i in range(blocks)]\n",
    "\n",
    "def cg_init_graph(A, b, state0, x_init=None, M=None, M12=None):\n",
    "    if x_init is not None and M is not None and M12 is None:\n",
    "        raise ValueError('warm start (x0) and preconditioner (M) given, M^{1/2} required')\n",
    "    x0, r0, p0 = map(lambda nm: nm + '-' + state0, ('x', 'r', 'p'))\n",
    "    scal_x = float(x_init is not None)\n",
    "    vec_x = b if x_init is None else x_init\n",
    "    def init_x(x_or_b): return scal_x * x_or_b\n",
    "    def init_p(ri): return 1 * ri\n",
    "    dsk = dict()\n",
    "    vblocks, hblocks = A.numblocks\n",
    "    for i in range(vblocks):\n",
    "        dsk[(x0, i)] = (init_x, (vec_x.name, i))\n",
    "    dsk.update(graph_gemv(-1, A, x0, 1, b.name, r0))\n",
    "    if M is None:\n",
    "        for i in range(vblocks):\n",
    "            dsk[(p0, i)] = (init_p, (r0, i))\n",
    "    else:\n",
    "        dsk.update(graph_dot(M, r0, p0))\n",
    "    return dsk\n",
    "\n",
    "def cg_iterate_graph(A, state0, state1, M=None):\n",
    "    Ap, pAp = 'Ap-' + state0, 'pAp-' + state0\n",
    "    x0, r0, p0, rMr0 = map(lambda nm: nm + '-' + state0, ('x', 'r', 'p', 'rMr'))\n",
    "    x1, r1, p1, rMr1 = map(lambda nm: nm + '-' + state1, ('x', 'r', 'p', 'rMr'))\n",
    "    def update_x(x, rMr, pAp, p): return x + (rMr / pAp) * p\n",
    "    def update_r(r, rMr, pAp, Ap): return r - (rMr / pAp) * Ap\n",
    "    def update_p(p, rMr, rMr_next, Mr): return Mr + (rMr_next / rMr) * p\n",
    "    dsk = dict()\n",
    "    vblocks, hblocks = A.numblocks\n",
    "    get_blocks = functools.partial(list_blocks, blocks=vblocks)\n",
    "    get_blocks_d = functools.partial(dict_blocks, blocks=vblocks)\n",
    "    dsk.update(graph_dot(A, p0, Ap))\n",
    "    if M is None:\n",
    "        dsk_Mr0 = {('Mr0', i): (r0, i) for i in range(vblocks)}\n",
    "        dsk_Mr1 = {('Mr1', i): (r1, i) for i in range(vblocks)}\n",
    "    else:\n",
    "        dsk_Mr0 = graph_dot(M, r0, 'Mr0')\n",
    "        dsk_Mr1 = graph_dot(M, r1, 'Mr1')\n",
    "    dsk[rMr0] = (da.core.dotmany, get_blocks(r0), get_blocks_d(dsk_Mr0, 'Mr0'))\n",
    "    dsk[rMr1] = (da.core.dotmany, get_blocks(r1), get_blocks_d(dsk_Mr1, 'Mr1'))\n",
    "\n",
    "    dsk[pAp] = (da.core.dotmany, get_blocks(p0), get_blocks(Ap))\n",
    "    for i in range(vblocks):\n",
    "        dsk[(x1, i)] = (update_x, (x0, i), rMr0, pAp, (p0, i))\n",
    "        dsk[(r1, i)] = (update_r, (r0, i), rMr0, pAp, (Ap, i))\n",
    "        dsk[(p1, i)] = (update_p, (p0, i), rMr0, rMr1, dsk_Mr1[('Mr1', i)])\n",
    "    return dsk\n",
    "\n",
    "def cg_calcs_proto(shape, chunks, dtype, dsk, key, optimize=False, **options):\n",
    "    if options.pop('finish', False):\n",
    "        dsk_final = dict()\n",
    "        key_final = 'cg-output'\n",
    "        for i in range(len(chunks[0])):\n",
    "            dsk_final[('x-' + key_final, i)] = ('x-' + key, i)\n",
    "            dsk_final[('r-' + key_final, i)] = ('r-' + key, i)\n",
    "            dsk_final[('p-' + key_final, i)] = ('p-' + key, i)\n",
    "            dsk = dask.sharedict.merge(dsk, dsk_final)\n",
    "        key = key_final\n",
    "    x = da.Array(dsk, 'x-' + key, shape=shape, chunks=chunks, dtype=dtype)\n",
    "    r = da.Array(dsk, 'r-' + key, shape=shape, chunks=chunks, dtype=dtype)\n",
    "    p = da.Array(dsk, 'p-' + key, shape=shape, chunks=chunks, dtype=dtype)\n",
    "    if optimize:\n",
    "        (x, r, p) = dask.optimize(x, r, p)\n",
    "    (x, r, p) = dask.persist(x, r, p, optimize_graph=False, traverse=False)\n",
    "    (res,) = dask.compute(da.linalg.norm(r))\n",
    "    return x, r, p, res\n",
    "\n",
    "def cg_graph(A, b, preconditioner=None, x_init=None, tol=1e-5, maxiter=500, **options):\n",
    "    M = preconditioner\n",
    "    M12 = options.pop('preconditioner12', None)\n",
    "    optimize = options.pop('optimize', False)\n",
    "    cg_calcs = functools.partial(cg_calcs_proto, b.shape, b.chunks, b.dtype, optimize=optimize)\n",
    "    graph_iters, print_iters, time_iters = iter_options(**options)\n",
    "    key_init = 'cg-iter0'\n",
    "    dsk = cg_init_graph(A, b, key_init, x_init=x_init, M=M, M12=M12)\n",
    "    dsks = [A.dask, b.dask, dsk]\n",
    "    dsks += [x_init.dask] if x_init is not None else []\n",
    "    dsks += [M.dask] if M is not None else []\n",
    "    x, r, p, res0 = cg_calcs(dask.sharedict.merge(*dsks), key_init, **options)\n",
    "    if res0 < tol or maxiter == 0:\n",
    "        return x, res0, 0\n",
    "\n",
    "    if time_iters > 0:\n",
    "        start = time.time()\n",
    "    dsk = dict()\n",
    "    for i in range(1, maxiter + 1):\n",
    "        key0 = 'cg-iter{}'.format(i - 1)\n",
    "        key1 = 'cg-iter{}'.format(i)\n",
    "        calculate = bool(i % graph_iters == 0)\n",
    "        dsk.update(cg_iterate_graph(A, key0, key1, M=M))\n",
    "        if calculate:\n",
    "            dsks = [A.dask, x.dask, r.dask, p.dask, dsk]\n",
    "            dsks += [M.dask] if M is not None else []\n",
    "            x, r, p, res = cg_calcs(dask.sharedict.merge(*dsks), key1)\n",
    "            dsk = dict()\n",
    "            if print_iters > 0 and i % print_iters == 0:\n",
    "                print '\\t\\t\\t{}: residual = {:.1e}'.format(i, res)\n",
    "            if res < tol:\n",
    "                break\n",
    "        if time_iters > 0 and i % time_iters == 0:\n",
    "            print '{}: {:.1e} seconds'.format(i, time.time() - start)\n",
    "            start = time.time()\n",
    "    dsks = [x.dask, r.dask, p.dask]\n",
    "    dsks += [A.dask, dsk] if i == maxiter else []\n",
    "    dsks += [M.dask] if (i == maxiter and M is not None) else []\n",
    "    x, _, _, res = cg_calcs(dask.sharedict.merge(*dsks), key1, finish=True)\n",
    "    return x, res, i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "AA = da.from_array(Acg, chunks=mc, name='A')\n",
    "bb = da.from_array(np.ones(m), chunks=mc, name='b')\n",
    "mdiag = da.from_array(1. / diagA, chunks=mc, name='M')\n",
    "MM = linop.DLODiagonal(mdiag)\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REPEAT_OLD:\n",
    "    start = time.time()\n",
    "    x, res, iters = cg_graph(AA, bb, time_iters=10, graph_iters=10)\n",
    "    print \"TOTAL\", time.time() - start, iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REPEAT_OLD:\n",
    "    start = time.time()\n",
    "    x, res, iters = cg_graph(AA, bb, time_iters=10, graph_iters=10, optimize=True)\n",
    "    print \"TOTAL\", time.time() - start, iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REPEAT_OLD:\n",
    "    start = time.time()\n",
    "    x, res, iters = cg_graph(AA, bb, preconditioner=MM, verbose=2, time_iters=5, graph_iters=10)\n",
    "    print \"TOTAL\", time.time() - start, iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REPEAT_OLD:\n",
    "    start = time.time()\n",
    "    x, res, iters = cg_graph(linop.DLODense(AA), bb, preconditioner=MM, verbose=2, time_iters=5, graph_iters=10)\n",
    "    print \"TOTAL\", time.time() - start, iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "Apy = np.random.normal(0, 1. / np.sqrt(m), (m + mc, m))\n",
    "AApy = Apy.T.dot(Apy)\n",
    "A_tall = da.from_array(Apy, chunks=mc, name='Atall')\n",
    "AA_dense = linop.DLODense(da.from_array(AApy, chunks=mc), name='gram2daskmat')\n",
    "AA_dlo = linop.DLOGram(da.from_array(Apy, chunks=mc), name='mat2daskgram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dask.array<x_out, shape=(1000,), dtype=float64, chunksize=(100,)>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsk = graph_dot(AA_dense, bb.name, 'x_out', transpose=True)\n",
    "dsk = dask.sharedict.merge(AA_dense.dask, bb.dask, dsk)\n",
    "x_out = da.Array(dsk, 'x_out', dtype=bb.dtype, chunks=bb.chunks, shape=bb.shape)\n",
    "x_out.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dask.array<x_out, shape=(1100,), dtype=float64, chunksize=(100,)>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsk = graph_dot(A_tall, bb.name, 'x_out')\n",
    "dsk = dask.sharedict.merge(A_tall.dask, bb.dask, dsk)\n",
    "x_out = da.Array(dsk, 'x_out', dtype=A_tall.dtype, chunks=(A_tall.chunks[0],), shape=(A_tall.shape[0],))\n",
    "x_out.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dask.array<y_out, shape=(1000,), dtype=float64, chunksize=(100,)>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsk = graph_dot(A_tall, x_out.name, 'y_out', tranpose=True)\n",
    "dsk = dask.sharedict.merge(A_tall.dask, x_out.dask, dsk)\n",
    "y_out = da.Array(dsk, 'y_out', dtype=A_tall.dtype, chunks=(A_tall.chunks[1],), shape=(A_tall.shape[1],))\n",
    "y_out.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dask.array<x-cg, shape=(1000,), dtype=float64, chunksize=(100,)>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsk = cg_init_graph(AA_dense, bb, 'cg-iter0', M=None)\n",
    "dsk = dask.sharedict.merge(AA_dense.dask, bb.dask, dsk)\n",
    "x_out = da.Array(dsk, 'x-cg-iter0', dtype=bb.dtype, chunks=bb.chunks, shape=bb.shape)\n",
    "x_out.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REPEAT_OLD:\n",
    "    start = time.time()\n",
    "    x, res, iters = cg_graph(AA_dense, bb, print_iters=10, time_iters=10, graph_iters=10)\n",
    "    print \"TOTAL\", time.time() - start, iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_array = functools.partial(da.Array, dtype=bb.dtype, chunks=bb.chunks, shape=bb.shape)\n",
    "dsk = cg_init_graph(AA_dlo, bb, 'cg-iter0', M=None)\n",
    "dsk = dask.sharedict.merge(AA_dlo.dask, bb.dask, dsk)\n",
    "x = get_array(dsk, 'x-cg-iter0')\n",
    "r = get_array(dsk, 'r-cg-iter0')\n",
    "p = get_array(dsk, 'p-cg-iter0')\n",
    "(x, r, p) = dask.persist(x, r, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REPEAT_OLD:\n",
    "    start = time.time()\n",
    "    x, res, iters = cg_graph(AA_dlo, bb, print_iters=10, time_iters=10, graph_iters=10)\n",
    "    print \"TOTAL\", time.time() - start, iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REPEAT_OLD:\n",
    "    start = time.time()\n",
    "    x, res, iters = cg_graph(AA_dlo, bb, print_iters=10, time_iters=10, graph_iters=30, optimize=True)\n",
    "    print \"TOTAL\", time.time() - start, iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REPEAT_OLD:\n",
    "    start = time.time()\n",
    "    x, res, iters = cg_graph(AA_dlo, bb, print_iters=10, time_iters=10, graph_iters=30)\n",
    "    print \"TOTAL\", time.time() - start, iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REPEAT_OLD:\n",
    "    MM_dlo = linop.DLODiagonal(da.from_array(1. / np.diag(AApy), chunks=mc))\n",
    "    start = time.time()\n",
    "    x, res, iters = cg_graph(AA_dlo, bb, preconditioner=MM_dlo, print_iters=10, time_iters=10, graph_iters=30)\n",
    "    print \"TOTAL\", time.time() - start, iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REPEAT_OLD:\n",
    "    AA_dlo = linop.DLORegularizedGram(A_tall)\n",
    "    MM_dlo = linop.DLODiagonal(da.from_array(1. / (1 + np.diag(AApy)), chunks=mc))\n",
    "    start = time.time()\n",
    "    x, res, iters = cg_graph(AA_dlo, bb, preconditioner=MM_dlo, print_iters=10, time_iters=10, graph_iters=30)\n",
    "    print \"TOTAL\", time.time() - start, iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REPEAT_OLD:\n",
    "    AA_dlo = linop.DLORegularizedGram(A_tall)\n",
    "    MM_dlo = linop.DLODiagonal(da.from_array(1. / (1 + np.diag(AApy)), chunks=mc))\n",
    "    start = time.time()\n",
    "    x, res, iters = cg_graph(AA_dlo, bb, preconditioner=MM_dlo, print_iters=10, time_iters=10, graph_iters=10)\n",
    "    print \"TOTAL\", time.time() - start, iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REPEAT_OLD:\n",
    "    AA_dlo = linop.DLORegularizedGram(A_tall)\n",
    "    MM_dlo = linop.DLODiagonal(da.from_array(1. / (1 + np.diag(AApy)), chunks=mc))\n",
    "    start = time.time()\n",
    "    x, res, iters = cg_graph(AA_dlo, bb, preconditioner=MM_dlo, print_iters=10, time_iters=10, graph_iters=20)\n",
    "    print \"TOTAL\", time.time() - start, iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REPEAT_OLD:\n",
    "    AA_dlo = linop.DLORegularizedGram(A_tall)\n",
    "    MM_dlo = linop.DLODiagonal(da.from_array(1. / (1 + np.diag(AApy)), chunks=mc))\n",
    "    start = time.time()\n",
    "    x, res, iters = cg_graph(AA_dlo, bb, preconditioner=MM_dlo, print_iters=10, time_iters=10, graph_iters=5)\n",
    "    print \"TOTAL\", time.time() - start, iters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### warm start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ensure variables built correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REPEAT_OLD:\n",
    "    x, res, iters = cg_graph(AA_dlo, bb, graph_iters=1, maxiter=300)\n",
    "    dsk = cg_init_graph(AA_dlo, bb, 'cg-iter0', x_init=x, M=None, M12=None)\n",
    "\n",
    "    build_array = functools.partial(da.Array, shape=x.shape, chunks=x.chunks, dtype=x.dtype)\n",
    "    build_array_m = functools.partial(da.Array, shape=(A_tall.shape[0],), chunks=(A_tall.chunks[0],), dtype=x.dtype)\n",
    "    dmerge = dask.sharedict.merge(AA_dlo.dask, bb.dask, x.dask, dsk)\n",
    "    x0 = build_array(dmerge, 'x-cg-iter0')\n",
    "    assert da.linalg.norm(x - x0).compute() < 1e-15 * (1 + np.sqrt(x0.size))\n",
    "    Ax0 = build_array_m(dmerge, 'DLO-gram-Atall-gramA-x-cg-iter0')\n",
    "    Ax0d = A_tall.dot(x)\n",
    "    assert da.linalg.norm(Ax0d - Ax0).compute() < 1e-15 * (1 + np.sqrt(Ax0.size))\n",
    "    AAx0 = build_array(dmerge, 'DLO-regularized-gram-Atall-gramAA-x-cg-iter0')\n",
    "    AAx0d = A_tall.T.dot(Ax0d)\n",
    "    assert da.linalg.norm(AAx0d - AAx0).compute() < 1e-15 * (1 + np.sqrt(AAx0.size))\n",
    "    IAAx0 = build_array(dmerge, 'DLO-regularized-gram-Atall-mul-x-cg-iter0')\n",
    "    IAAx0d = x + AAx0d\n",
    "    assert da.linalg.norm(IAAx0d - IAAx0).compute() < 1e-15 * (1 + np.sqrt(IAAx0.size))\n",
    "    r0 = build_array(dmerge, 'r-cg-iter0')\n",
    "    r0d = IAAx0d - bb\n",
    "    assert da.linalg.norm(r0 - r0d).compute() < 1e-15 * (1 + np.sqrt(r0.size))\n",
    "    print 'all pass'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ensure residual small on warmstart "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REPEAT_OLD:\n",
    "    x, res, iters = cg_graph(AA_dlo, bb, graph_iters=1, maxiter=300)\n",
    "    dsk = cg_init_graph(AA_dlo, bb, 'cg-iter0', x_init=x, M=None, M12=None)\n",
    "    dmerge = dask.sharedict.merge(AA_dlo.dask, bb.dask, x.dask, dsk)\n",
    "    r0 = build_array(dmerge, 'r-cg-iter0')\n",
    "    assert da.linalg.norm(r0).compute() - res < 1e-15 * (1 + np.sqrt(r0.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ensure 0 iterations on exact warmstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REPEAT_OLD:\n",
    "    x, res, iters = cg_graph(AA_dlo, bb, graph_iters=1, maxiter=300)\n",
    "    x_ws, res_ws, iters_ws = cg_graph(AA_dlo, bb, x_init=x, graph_iters=1, maxiter=300)\n",
    "    assert iters_ws == 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ensure iterations deterministic w/ warmstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REPEAT_OLD:\n",
    "    x, res, iters = cg_graph(AA_dlo, bb, graph_iters=1, maxiter=300)\n",
    "    x_partial, res_partial, iters_partial = cg_graph(AA_dlo, bb, graph_iters=1, maxiter=10)\n",
    "    x_ws, res_ws, iters_ws = cg_graph(AA_dlo, bb, x_init=x_partial, graph_iters=1, maxiter=300)\n",
    "    assert iters_partial + iters_ws == iters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- try nearby b: |r_0| = |Ax0 - b_perturb| =approx= |b - b_perturb|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REPEAT_OLD:\n",
    "    bb_perturb = bb * (1 + da.random.normal(0, 0.001, m, chunks=mc))\n",
    "    x, res, iters = cg_graph(AA_dlo, bb, graph_iters=1, maxiter=300)\n",
    "    dsk = cg_init_graph(AA_dlo, bb_perturb, 'cg-iter0', x_init=x, M=None, M12=None)\n",
    "    dmerge = dask.sharedict.merge(AA_dlo.dask, bb_perturb.dask, x.dask, dsk)\n",
    "    r0 = build_array(dmerge, 'r-cg-iter0')\n",
    "    assert da.linalg.norm(r0).compute() - da.linalg.norm(bb - bb_perturb).compute() < res \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- try nearby b: iters(A, b_perturb, x^\\star)  < iters(A, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REPEAT_OLD:\n",
    "    bb_perturb = bb * (1 + da.random.normal(0, 0.001, m, chunks=mc))\n",
    "    x, res, iters = cg_graph(AA_dlo, bb, graph_iters=1, maxiter=300)\n",
    "    x_perturb, res_perturb, iters_perturb = cg_graph(AA_dlo, bb_perturb, x_init=x, graph_iters=1, maxiter=300)\n",
    "    print iters, iters_perturb\n",
    "    assert iters > iters_perturb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- try nearby x:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REPEAT_OLD:\n",
    "    perturb = 0.1 * da.mean(x).compute() / (x.size**0.5)\n",
    "    x, res, iters = cg_graph(AA_dlo, bb, graph_iters=1, maxiter=300)\n",
    "    x0 = x * (1 + da.random.normal(0, perturb, m, chunks=mc))\n",
    "    x_perturb, res_perturb, iters_perturb = cg_graph(AA_dlo, bb, x_init=x_perturb, graph_iters=1, maxiter=300)\n",
    "    print iters, iters_perturb\n",
    "    assert iters > iters_perturb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- try nearby x, b:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REPEAT_OLD:\n",
    "    x, res, iters = cg_graph(AA_dlo, bb, graph_iters=1, maxiter=300)\n",
    "    perturb_x = 0.1 * da.mean(x).compute() / (x.size**0.5)\n",
    "    perturb_b = 0.1 * da.mean(bb).compute() / (bb.size**0.5)\n",
    "    xp = x * (1 + da.random.normal(0, perturb_x, m, chunks=mc))\n",
    "    bbp = bb * (1 + da.random.normal(0, perturb_b, m, chunks=mc))\n",
    "    x_perturb, res_perturb, iters_perturb = cg_graph(AA_dlo, bbp, x_init=xp, graph_iters=1, maxiter=300)\n",
    "    print iters, iters_perturb\n",
    "    assert iters > iters_perturb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph projection\n",
    "\n",
    "- solve (I + A'A)x = A'y + xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "GP_TEST0 = REPEAT_OLD\n",
    "if GP_TEST0:\n",
    "    AA_dlo.regularization = 1\n",
    "    yy = da.random.random(A_tall.shape[0], chunks=mc)\n",
    "    xx = 0\n",
    "    ATyx = A_tall.T.dot(yy) + xx\n",
    "    yy, ATyy = dask.persist(yy, ATyx)\n",
    "    x_out, res, iters = cg_graph(AA_dlo, ATyx, tol=1e-8, print_iters=10, graph_iters=1, maxiter=300)\n",
    "    y_out = A_tall.dot(x).persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if GP_TEST0:\n",
    "    ATyx_next = A_tall.T.dot(y_out) + x_out\n",
    "    ATyx_next.persist()\n",
    "    x_next, res_next, iters_next = cg_graph(AA_dlo, ATyx_next, tol=1e-8, print_iters=10, graph_iters=1, maxiter=300)\n",
    "    assert da.linalg.norm(x_next - x_out).compute() < 1e-15 * (1 + x.size**0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CGLS $$\\mathrm{minimize }\\quad \\|Ax - b\\|_2^2 + \\rho\\|x\\|_2^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cgls(A, b, rho, **options):\n",
    "    b_hat = da.dot(A.T, b)\n",
    "    A_hat = linop.DLORegularizedGram(A, regularization=rho, transpose=False)\n",
    "    return cg_graph(A_hat, b_hat, **options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "CGLS_TALL = REPEAT_OLD\n",
    "# CGLS_TALL = True\n",
    "if CGLS_TALL:\n",
    "    y_in = da.random.random(A_tall.shape[0], chunks=mc)\n",
    "    x_in = da.random.random(A_tall.shape[1], chunks=mc)\n",
    "    Ax_in = A_tall.dot(x_in)\n",
    "    b_in = y_in - Ax_in\n",
    "    A_tall, b_in = dask.persist(A_tall, b_in)\n",
    "    x, res, iters = cgls(A_tall, b_in, 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CGLS_TALL:\n",
    "    x_in = da.random.random(A_tall.shape[1], chunks=mc)\n",
    "    y_in = A_tall.dot(x_in)\n",
    "    b_in = y_in - Ax_in\n",
    "    A_tall, b_in = dask.persist(A_tall, b_in)\n",
    "    x, res, iters = cgls(A_tall, b_in, 1.)\n",
    "    x_out = x + x_in \n",
    "    y_out = A_tall.dot(x_out)\n",
    "    x_out, y_out = dask.persist(x_out, y_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fat CG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_fat = (A_tall.T).persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CG fat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Afat_gram = linop.DLOGram(A_fat)\n",
    "b_fat = da.ones(Afat_gram.shape[1], chunks=mc)\n",
    "A_fat, b_fat = dask.persist(A_fat, b_fat)\n",
    "build_array = functools.partial(da.Array, dtype=b_fat.dtype, chunks=b_fat.chunks, shape=b_fat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsk = cg_init_graph(Afat_gram, b_fat, 'cg-iter0')\n",
    "dsk = dask.sharedict.merge(dsk, Afat_gram.dask, b_fat.dask)\n",
    "x = build_array(dsk, 'x-cg-iter0').persist()\n",
    "r = build_array(dsk, 'r-cg-iter0')\n",
    "p = build_array(dsk, 'p-cg-iter0')\n",
    "x, r, p = dask.persist(x, r, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsk = cg_iterate_graph(Afat_gram, 'cg-iter0', 'cg-iter1')\n",
    "dsk = dask.sharedict.merge(dsk, Afat_gram.dask, x.dask, r.dask, p.dask)\n",
    "x = build_array(dsk, 'x-cg-iter0')\n",
    "r = build_array(dsk, 'x-cg-iter0')\n",
    "p = build_array(dsk, 'x-cg-iter0')\n",
    "x, r, p = dask.persist(x, r, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REPEAT_OLD:\n",
    "# if True:\n",
    "    x, res, i = cg_graph(Afat_gram, b_fat, print_iters=10, graph_iters=10)\n",
    "    print res, i\n",
    "    print x.shape, Afat_gram.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CG fat w/ forced form $$A_{gram} = A^TA$$\n",
    "- convergence not expected since A'A singular for A fat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATA_fat = linop.DLOGram(A_fat, transpose=False)\n",
    "b_fat = da.ones(ATA_fat.shape[1], chunks=mc)\n",
    "A_fat, b_fat = dask.persist(A_fat, b_fat)\n",
    "build_array = functools.partial(da.Array, dtype=b_fat.dtype, chunks=b_fat.chunks, shape=b_fat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsk = cg_init_graph(ATA_fat, b_fat, 'cg-iter0')\n",
    "dsk = dask.sharedict.merge(dsk, ATA_fat.dask, b_fat.dask)\n",
    "x = build_array(dsk, 'x-cg-iter0')\n",
    "r = build_array(dsk, 'r-cg-iter0')\n",
    "p = build_array(dsk, 'p-cg-iter0')\n",
    "x, r, p = dask.persist(x, r, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsk = cg_iterate_graph(ATA_fat, 'cg-iter0', 'cg-iter1')\n",
    "dsk = dask.sharedict.merge(dsk, ATA_fat.dask, x.dask, r.dask, p.dask)\n",
    "x = build_array(dsk, 'x-cg-iter0')\n",
    "r = build_array(dsk, 'r-cg-iter0')\n",
    "p = build_array(dsk, 'p-cg-iter0')\n",
    "x, r, p = dask.persist(x, r, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REPEAT_OLD:\n",
    "# if True:\n",
    "    x, res, i = cg_graph(ATA_fat, b_fat, print_iters=10, graph_iters=10)\n",
    "    print res, i\n",
    "    print x.shape, ATA_fat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CG fat regularized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Afat_rgram = linop.DLORegularizedGram(A_fat)\n",
    "b_fat = da.ones(Afat_rgram.shape[1], chunks=mc)\n",
    "A_fat, b_fat = dask.persist(A_fat, b_fat)\n",
    "build_array = functools.partial(da.Array, dtype=b_fat.dtype, chunks=b_fat.chunks, shape=b_fat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsk = cg_init_graph(Afat_rgram, b_fat, 'cg-iter0')\n",
    "dsk = dask.sharedict.merge(dsk, Afat_gram.dask, b_fat.dask)\n",
    "x = build_array(dsk, 'x-cg-iter0')\n",
    "r = build_array(dsk, 'r-cg-iter0')\n",
    "p = build_array(dsk, 'p-cg-iter0')\n",
    "x, r, p = dask.persist(x, r, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dsk = cg_iterate_graph(Afat_rgram, 'cg-iter0', 'cg-iter1')\n",
    "dsk = dask.sharedict.merge(dsk, Afat_rgram.dask, x.dask, r.dask, p.dask)\n",
    "x = build_array(dsk, 'x-cg-iter0')\n",
    "r = build_array(dsk, 'r-cg-iter0')\n",
    "p = build_array(dsk, 'p-cg-iter0')\n",
    "x, r, p = dask.persist(x, r, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REPEAT_OLD:\n",
    "# if True:\n",
    "    x, res, i = cg_graph(Afat_rgram, b_fat, print_iters=10, graph_iters=10)\n",
    "    print res, i\n",
    "    print x.shape, Afat_rgram.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CG fat regularized with forced form $$A_{gram} = A^TA$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATA_fatreg = linop.DLORegularizedGram(A_fat, transpose=False)\n",
    "b_fatreg = da.ones(ATA_fatreg.shape[1], chunks=mc)\n",
    "A_fat, b_fatreg = dask.persist(A_fat, b_fatreg)\n",
    "build_array = functools.partial(da.Array, dtype=A_fat.dtype, chunks=(A_fat.chunks[1],), shape=(A_fat.shape[1],))\n",
    "build_array_m = functools.partial(da.Array, dtype=A_fat.dtype, chunks=(A_fat.chunks[0],), shape=(A_fat.shape[0],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsk = cg_init_graph(ATA_fatreg, b_fatreg, 'cg-iter0')\n",
    "dsk = dask.sharedict.merge(dsk, ATA_fatreg.dask, b_fatreg.dask)\n",
    "x = build_array(dsk, 'x-cg-iter0')\n",
    "r = build_array(dsk, 'r-cg-iter0')\n",
    "p = build_array(dsk, 'p-cg-iter0')\n",
    "x, r, p = dask.persist(x, r, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsk = cg_iterate_graph(ATA_fatreg, 'cg-iter0', 'cg-iter1')\n",
    "dsk = dask.sharedict.merge(dsk, ATA_fatreg.dask, x.dask, r.dask, p.dask)\n",
    "x = build_array(dsk, 'x-cg-iter0')\n",
    "r = build_array(dsk, 'r-cg-iter0')\n",
    "p = build_array(dsk, 'p-cg-iter0')\n",
    "x, r, p = dask.persist(x, r, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t10: residual = 3.7e-03\n",
      "\t\t\t20: residual = 2.7e-07\n",
      "2.7277470348e-07 20\n",
      "(1100,) (1100, 1100)\n"
     ]
    }
   ],
   "source": [
    "if REPEAT_OLD:\n",
    "# if True:\n",
    "    x, res, i = cg_graph(ATA_fatreg, b_fatreg, print_iters=10, graph_iters=10, maxiter=300)\n",
    "    print res, i\n",
    "    print x.shape, ATA_fatreg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "CGLS_FAT = REPEAT_OLD\n",
    "# CGLS_FAT = True\n",
    "if CGLS_FAT:\n",
    "    y_in = da.random.random(A_fat.shape[0], chunks=mc)\n",
    "    x_in = da.random.random(A_fat.shape[1], chunks=mc)\n",
    "    Ax_in = A_fat.dot(x_in)\n",
    "    b_in = y_in - Ax_in\n",
    "    A_tall, b_in = dask.persist(A_fat, b_in)\n",
    "    x, res, iters = cgls(A_fat, b_in, 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if CGLS_FAT:\n",
    "    x_in = da.random.random(A_fat.shape[1], chunks=mc)\n",
    "    y_in = A_fat.dot(x_in)\n",
    "    b_in = y_in - Ax_in\n",
    "    A_fat, b_in = dask.persist(A_fat, b_in)\n",
    "    x, res, iters = cgls(A_fat, b_in, 1.)\n",
    "    x_out = x + x_in \n",
    "    y_out = A_fat.dot(x_out)\n",
    "    x_out, y_out = dask.persist(x_out, y_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph projection methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CGLS: update $$x = x_0 + \\mathrm{argmin}_x \\|Ax - (y_0 - Ax_0)\\| + \\|x\\|_2 \\\\ y = Ax$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cgls_project(A, x, y, tol=1e-8, **options):\n",
    "    b = y - A.dot(x)\n",
    "    A, b = dask.persist(A, b)\n",
    "    x_cg, res, iters  = cgls(A, b, 1, tol=tol)\n",
    "    x_out = x + x_cg\n",
    "    y_out = A.dot(x_out)\n",
    "    x_out, y_out = dask.persist(x_out, y_out)\n",
    "    return x_out, y_out, res, iters    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REPEAT_OLD:\n",
    "    xrand = da.random.random(A_tall.shape[1], chunks=mc)\n",
    "    yrand = da.random.random(A_tall.shape[0], chunks=mc)\n",
    "    start = time.time()\n",
    "    xo, yo, res, iters = cgls_project(A_tall, xrand, yrand)\n",
    "    print \"first solve time\", time.time() - start\n",
    "    xoo, yoo, res_, iters_ = cgls_project(A_tall, xo, yo)\n",
    "    print iters\n",
    "    assert iters_ == 0\n",
    "    assert da.linalg.norm(xo - xoo) < 1e-15 * (1 + xo.size**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REPEAT_OLD:\n",
    "# if True:\n",
    "    xrand = da.random.random(A_fat.shape[1], chunks=mc)\n",
    "    yrand = da.random.random(A_fat.shape[0], chunks=mc)\n",
    "    start = time.time()\n",
    "    xo, yo, res, iters = cgls_project(A_fat, xrand, yrand)\n",
    "    print \"first solve time\", time.time() - start\n",
    "    xoo, yoo, res_, iters_ = cgls_project(A_fat, xo, yo)\n",
    "    print iters\n",
    "    assert iters_ == 0\n",
    "    assert da.linalg.norm(xo - xoo) < 1e-15 * (1 + xo.size**0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CG: update $$x = (I + A^TA)^{-1}(A^Ty_0 + x_0) \\\\y = Ax$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cg_project(A, x, y, tol=1e-8, **options):\n",
    "    b = A.T.dot(y) + x\n",
    "    A_hat = linop.DLORegularizedGram(A, transpose=False)\n",
    "    x_out, res, iters = cg_graph(A_hat, b, tol=tol, **options)\n",
    "    y_out = A.dot(x_out)\n",
    "    x_out, y_out = dask.persist(x_out, y_out)\n",
    "    return x_out, y_out, res, iters    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first solve time 3.06351184845\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "# if REPEAT_OLD:\n",
    "if True:\n",
    "    xrand = da.random.random(A_tall.shape[1], chunks=mc)\n",
    "    yrand = da.random.random(A_tall.shape[0], chunks=mc)\n",
    "    start = time.time()\n",
    "    xo, yo, res, iters = cg_project(A_tall, xrand, yrand)\n",
    "    print \"first solve time\", time.time() - start\n",
    "    xoo, yoo, res_, iters_ = cg_project(A_tall, xo, yo, x_init=xo)\n",
    "    print iters\n",
    "    assert iters_ == 0\n",
    "    assert da.linalg.norm(xo - xoo) < 1e-15 * (1 + xo.size**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first solve time 3.00991201401\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "# if REPEAT_OLD:\n",
    "if True:\n",
    "    xrand = da.random.random(A_fat.shape[1], chunks=mc)\n",
    "    yrand = da.random.random(A_fat.shape[0], chunks=mc)\n",
    "    start = time.time()\n",
    "    xo, yo, res, iters = cg_project(A_fat, xrand, yrand)\n",
    "    print \"first solve time\", time.time() - start\n",
    "    xoo, yoo, res_, iters_ = cg_project(A_fat, xo, yo, x_init=xo)\n",
    "    print iters\n",
    "    assert iters_ == 0\n",
    "    assert da.linalg.norm(xo - xoo) < 1e-15 * (1 + xo.size**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
